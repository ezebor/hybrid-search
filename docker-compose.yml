version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.3.0
    container_name: broker
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

  redis:
    image: redis:7-alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
    restart: always

  chroma:
    image: chromadb/chroma:0.5.0
    container_name: chroma-db
    ports:
      - "8000:8000"
    volumes:
      - chroma_data:/chroma/chroma
    restart: always

  # --- API Server Container ---
  api_server:
    build: . # Build the image using the Dockerfile in the current directory
    container_name: api_server
    command: python main.py # The command to run when the container starts
    ports:
      - "5000:5000" # Map host port 5000 to container port 5000
    volumes:
      - .:/app # Mount local code for live-reloading during development
    depends_on:
      - broker
      - redis
      - chroma
    restart: always

  # --- Kafka Consumer Container ---
  kafka_consumer:
    build: . # Re-use the same image built for the api_server
    container_name: kafka_consumer
    command: python consumers.py # Run the consumer script instead of the main API
    volumes:
      - .:/app
    depends_on:
      - broker
      - chroma
    restart: always

volumes:
  chroma_data:

